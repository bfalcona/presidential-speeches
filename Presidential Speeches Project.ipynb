{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def penntag_to_wordnettag(tag):\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif tag.startswith(\"VB\"):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif tag.startswith(\"JJ\"):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif tag.startswith(\"RB\"):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    \n",
    "common_terms = [\"America\", \"American\", \"Americans\", \"Applause.\", \"Applause\", \"applause.\", \"applause\", \"back\",\n",
    "                \"Congress\", \"could\", \"country\", \"good\", \"government\", \"know\", \"like\", \"make\", \"must\", \"nation\",\n",
    "                \"people\", \"President\", \"president\", \"United\", \"States\", \"They\", \"they\", \"this\", \"want\", \"would\",\n",
    "                \"year\",\"great\", \"national\", \"need\", \"many\", \"well\", \"take\", \"this\", \"trump\", \"think\", \"happen\",\n",
    "                \"vote\", \"world\", \"time\", \"come\", \"life\", \"look\", \"never\", \"This\", \"upon\", \"purpose\", \"shall\", \"goal\",\n",
    "                \"first\", \"every\", \"work\", \"help\", \"today\", \"meet\", \"tonight\", \"federal\", \"last\", \"right\", \"tell\",\n",
    "                \"thing\", \"that\", \"much\", \"south\", \"South\", \"also\", \"believe\", \"north\", \"North\", \"east\", \"East\",\n",
    "                \"program\", \"state\", \"policy\", \"increase\", \"thank\", \"give\", \"percent\", \"booing\", \"decision\", \"problem\",\n",
    "                \"well\", \"begin\", \"APPLAUSE\", \"TRUMP\", \"HILLARY\", \"CLINTON\", \"office\", \"Well\", \"Hillary\", \"Clinton\",\n",
    "                \"Trump\", \"audience\", \"bring\", \"BOOING\", \"Thank\", \"That\", \"that\", \"Ever\", \"ever\", \"AUDIENCE\", \"Even\",\n",
    "                \"even\", \"continue\", \"folk\", \"Folk\", \"leave\", \"Leave\", \"talk\", \"Talk\", \"Lose\", \"lose\", \"Really\",\n",
    "                \"really\", \"Million\", \"million\", \"Care\", \"care\", \"Place\", \"place\", \"mean\", \"Mean\", \"Love\", \"love\",\n",
    "                \"Start\", \"start\", \"city\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dwight D. Eisenhower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.000*\"peace\" + 0.000*\"free\" + 0.000*\"soviet\" + 0.000*\"area\" + 0.000*\"faith\" + 0.000*\"future\" + 0.000*\"power\" + 0.000*\"security\" + 0.000*\"atomic\" + 0.000*\"hope\"')\n",
      "(1, '0.011*\"peace\" + 0.009*\"free\" + 0.006*\"soviet\" + 0.005*\"hope\" + 0.005*\"future\" + 0.005*\"party\" + 0.005*\"atomic\" + 0.005*\"power\" + 0.004*\"security\" + 0.004*\"freedom\"')\n",
      "(2, '0.000*\"free\" + 0.000*\"peace\" + 0.000*\"soviet\" + 0.000*\"power\" + 0.000*\"atomic\" + 0.000*\"faith\" + 0.000*\"party\" + 0.000*\"principle\" + 0.000*\"hope\" + 0.000*\"security\"')\n",
      "(3, '0.000*\"peace\" + 0.000*\"free\" + 0.000*\"soviet\" + 0.000*\"nations\" + 0.000*\"atomic\" + 0.000*\"security\" + 0.000*\"power\" + 0.000*\"future\" + 0.000*\"military\" + 0.000*\"party\"')\n",
      "(4, '0.000*\"peace\" + 0.000*\"free\" + 0.000*\"soviet\" + 0.000*\"hope\" + 0.000*\"power\" + 0.000*\"future\" + 0.000*\"party\" + 0.000*\"strength\" + 0.000*\"nations\" + 0.000*\"principle\"')\n"
     ]
    }
   ],
   "source": [
    "eisenhower_path = Path(\"presidential_speeches/eisenhower\")\n",
    "\n",
    "eisenhower_files = [ ]\n",
    "for file in eisenhower_path.iterdir():\n",
    "    if file.name != \".DS_Store\":\n",
    "        eisenhower_files.append(file)\n",
    "\n",
    "with open(\"output_file\", \"w\") as outfile:\n",
    "    for fname in eisenhower_files:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "with open(\"output_file\") as f:\n",
    "    eisenhower_uncleaned = f.read()\n",
    "\n",
    "eisenhower_tagged = nltk.pos_tag(nltk.word_tokenize(eisenhower_uncleaned))\n",
    "\n",
    "eisenhower_lemmatized = [ ]\n",
    "for word, tag in eisenhower_tagged:\n",
    "    wntag = penntag_to_wordnettag(tag)\n",
    "    eisenhower_lemmatized.append(lemmatizer.lemmatize(word, wntag))\n",
    "\n",
    "eisenhower_text = [ ]\n",
    "for word in eisenhower_lemmatized:\n",
    "    if word not in stopwords and word not in common_terms and len(word) >= 4 and word.strip(string.punctuation) != \"\":\n",
    "        eisenhower_text.append(word.lower())\n",
    "\n",
    "eisenhower_corpus = [ ]\n",
    "eisenhower_corpus.append(eisenhower_text)\n",
    "\n",
    "eisenhower_dictionary = gensim.corpora.Dictionary(eisenhower_corpus)\n",
    "eisenhower_gensim = [ ]\n",
    "for document in eisenhower_corpus:\n",
    "    eisenhower_gensim.append(eisenhower_dictionary.doc2bow(document))\n",
    "\n",
    "eisenhower_model = gensim.models.ldamodel.LdaModel(eisenhower_gensim,\n",
    "                                               num_topics = 5,\n",
    "                                               id2word = eisenhower_dictionary,\n",
    "                                               passes = 20, iterations = 500,\n",
    "                                               alpha = \"asymmetric\",\n",
    "                                               random_state = 0)\n",
    "\n",
    "for topic in eisenhower_model.print_topics(num_words = 10):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Richard Nixon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.000*\"vietnam\" + 0.000*\"peace\" + 0.000*\"force\" + 0.000*\"action\" + 0.000*\"watergate\" + 0.000*\"history\" + 0.000*\"power\" + 0.000*\"hope\" + 0.000*\"concern\" + 0.000*\"negotiation\"')\n",
      "(1, '0.000*\"vietnam\" + 0.000*\"peace\" + 0.000*\"force\" + 0.000*\"vietnamese\" + 0.000*\"watergate\" + 0.000*\"full\" + 0.000*\"action\" + 0.000*\"together\" + 0.000*\"house\" + 0.000*\"strong\"')\n",
      "(2, '0.000*\"peace\" + 0.000*\"vietnam\" + 0.000*\"home\" + 0.000*\"force\" + 0.000*\"action\" + 0.000*\"become\" + 0.000*\"effort\" + 0.000*\"responsibility\" + 0.000*\"history\" + 0.000*\"power\"')\n",
      "(3, '0.000*\"peace\" + 0.000*\"vietnam\" + 0.000*\"action\" + 0.000*\"house\" + 0.000*\"future\" + 0.000*\"power\" + 0.000*\"question\" + 0.000*\"support\" + 0.000*\"force\" + 0.000*\"responsibility\"')\n",
      "(4, '0.014*\"peace\" + 0.010*\"vietnam\" + 0.004*\"force\" + 0.004*\"action\" + 0.003*\"responsibility\" + 0.003*\"vietnamese\" + 0.003*\"future\" + 0.003*\"watergate\" + 0.003*\"negotiation\" + 0.003*\"house\"')\n"
     ]
    }
   ],
   "source": [
    "dtype = np.float64\n",
    "\n",
    "nixon_path = Path(\"presidential_speeches/nixon\")\n",
    "\n",
    "nixon_files = [ ]\n",
    "for file in nixon_path.iterdir():\n",
    "    if file.name != \".DS_Store\":\n",
    "        nixon_files.append(file)\n",
    "\n",
    "with open(\"output_file\", \"w\") as outfile:\n",
    "    for fname in nixon_files:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "with open(\"output_file\") as f:\n",
    "    nixon_uncleaned = f.read()\n",
    "\n",
    "nixon_tagged = nltk.pos_tag(nltk.word_tokenize(nixon_uncleaned))\n",
    "\n",
    "nixon_lemmatized = [ ]\n",
    "for word, tag in nixon_tagged:\n",
    "    wntag = penntag_to_wordnettag(tag)\n",
    "    nixon_lemmatized.append(lemmatizer.lemmatize(word, wntag))\n",
    "\n",
    "nixon_text = [ ]\n",
    "for word in nixon_lemmatized:\n",
    "    if word not in stopwords and word not in common_terms and len(word) >= 4 and word.strip(string.punctuation) != \"\":\n",
    "        nixon_text.append(word.lower())\n",
    "\n",
    "nixon_corpus = [ ]\n",
    "nixon_corpus.append(nixon_text)\n",
    "\n",
    "nixon_dictionary = gensim.corpora.Dictionary(nixon_corpus)\n",
    "nixon_gensim = [ ]\n",
    "for document in nixon_corpus:\n",
    "    nixon_gensim.append(nixon_dictionary.doc2bow(document))\n",
    "\n",
    "nixon_model = gensim.models.ldamodel.LdaModel(nixon_gensim,\n",
    "                                               num_topics = 5,\n",
    "                                               id2word = nixon_dictionary,\n",
    "                                               passes = 20, iterations = 500,\n",
    "                                               alpha = \"asymmetric\",\n",
    "                                               random_state = 0)\n",
    "\n",
    "for topic in nixon_model.print_topics(num_words = 10):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerald Ford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.000*\"energy\" + 0.000*\"peace\" + 0.000*\"economic\" + 0.000*\"economy\" + 0.000*\"food\" + 0.000*\"foreign\" + 0.000*\"union\" + 0.000*\"future\" + 0.000*\"home\" + 0.000*\"inflation\"')\n",
      "(1, '0.000*\"energy\" + 0.000*\"peace\" + 0.000*\"future\" + 0.000*\"foreign\" + 0.000*\"economic\" + 0.000*\"europe\" + 0.000*\"food\" + 0.000*\"action\" + 0.000*\"inflation\" + 0.000*\"price\"')\n",
      "(2, '0.000*\"energy\" + 0.000*\"europe\" + 0.000*\"foreign\" + 0.000*\"achieve\" + 0.000*\"economic\" + 0.000*\"food\" + 0.000*\"future\" + 0.000*\"price\" + 0.000*\"action\" + 0.000*\"peace\"')\n",
      "(3, '0.000*\"energy\" + 0.000*\"peace\" + 0.000*\"future\" + 0.000*\"economic\" + 0.000*\"power\" + 0.000*\"union\" + 0.000*\"foreign\" + 0.000*\"food\" + 0.000*\"economy\" + 0.000*\"security\"')\n",
      "(4, '0.008*\"energy\" + 0.005*\"peace\" + 0.005*\"future\" + 0.004*\"economic\" + 0.004*\"foreign\" + 0.003*\"food\" + 0.003*\"security\" + 0.003*\"economy\" + 0.003*\"price\" + 0.003*\"union\"')\n"
     ]
    }
   ],
   "source": [
    "ford_path = Path(\"presidential_speeches/ford\")\n",
    "\n",
    "ford_files = [ ]\n",
    "for file in ford_path.iterdir():\n",
    "    if file.name != \".DS_Store\":\n",
    "        ford_files.append(file)\n",
    "\n",
    "with open(\"output_file\", \"w\") as outfile:\n",
    "    for fname in ford_files:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "with open(\"output_file\") as f:\n",
    "    ford_uncleaned = f.read()\n",
    "\n",
    "ford_tagged = nltk.pos_tag(nltk.word_tokenize(ford_uncleaned))\n",
    "\n",
    "ford_lemmatized = [ ]\n",
    "for word, tag in ford_tagged:\n",
    "    wntag = penntag_to_wordnettag(tag)\n",
    "    ford_lemmatized.append(lemmatizer.lemmatize(word, wntag))\n",
    "\n",
    "ford_text = [ ]\n",
    "for word in ford_lemmatized:\n",
    "    if word not in stopwords and word not in common_terms and len(word) >= 4 and word.strip(string.punctuation) != \"\":\n",
    "        ford_text.append(word.lower())\n",
    "\n",
    "ford_corpus = [ ]\n",
    "ford_corpus.append(ford_text)\n",
    "\n",
    "ford_dictionary = gensim.corpora.Dictionary(ford_corpus)\n",
    "ford_gensim = [ ]\n",
    "for document in ford_corpus:\n",
    "    ford_gensim.append(ford_dictionary.doc2bow(document))\n",
    "\n",
    "ford_model = gensim.models.ldamodel.LdaModel(ford_gensim,\n",
    "                                               num_topics = 5,\n",
    "                                               id2word = ford_dictionary,\n",
    "                                               passes = 20, iterations = 500,\n",
    "                                               alpha = \"asymmetric\",\n",
    "                                               random_state = 0)\n",
    "\n",
    "for topic in ford_model.print_topics(num_words = 10):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ronald Reagan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.000*\"peace\" + 0.000*\"soviet\" + 0.000*\"freedom\" + 0.000*\"force\" + 0.000*\"union\" + 0.000*\"economic\" + 0.000*\"together\" + 0.000*\"family\" + 0.000*\"future\" + 0.000*\"hope\"')\n",
      "(1, '0.000*\"freedom\" + 0.000*\"peace\" + 0.000*\"soviet\" + 0.000*\"force\" + 0.000*\"economic\" + 0.000*\"free\" + 0.000*\"human\" + 0.000*\"there\" + 0.000*\"hope\" + 0.000*\"family\"')\n",
      "(2, '0.007*\"peace\" + 0.006*\"freedom\" + 0.005*\"soviet\" + 0.004*\"force\" + 0.004*\"economic\" + 0.003*\"free\" + 0.003*\"hope\" + 0.003*\"family\" + 0.003*\"union\" + 0.003*\"future\"')\n",
      "(3, '0.000*\"peace\" + 0.000*\"freedom\" + 0.000*\"soviet\" + 0.000*\"force\" + 0.000*\"free\" + 0.000*\"economic\" + 0.000*\"hope\" + 0.000*\"future\" + 0.000*\"defense\" + 0.000*\"child\"')\n",
      "(4, '0.000*\"peace\" + 0.000*\"freedom\" + 0.000*\"economic\" + 0.000*\"force\" + 0.000*\"soviet\" + 0.000*\"support\" + 0.000*\"child\" + 0.000*\"family\" + 0.000*\"together\" + 0.000*\"there\"')\n"
     ]
    }
   ],
   "source": [
    "reagan_path = Path(\"presidential_speeches/reagan\")\n",
    "\n",
    "reagan_files = [ ]\n",
    "for file in reagan_path.iterdir():\n",
    "    if file.name != \".DS_Store\":\n",
    "        reagan_files.append(file)\n",
    "\n",
    "with open(\"output_file\", \"w\") as outfile:\n",
    "    for fname in reagan_files:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "with open(\"output_file\") as f:\n",
    "    reagan_uncleaned = f.read()\n",
    "\n",
    "reagan_tagged = nltk.pos_tag(nltk.word_tokenize(reagan_uncleaned))\n",
    "\n",
    "reagan_lemmatized = [ ]\n",
    "for word, tag in reagan_tagged:\n",
    "    wntag = penntag_to_wordnettag(tag)\n",
    "    reagan_lemmatized.append(lemmatizer.lemmatize(word, wntag))\n",
    "\n",
    "reagan_text = [ ]\n",
    "for word in reagan_lemmatized:\n",
    "    if word not in stopwords and word not in common_terms and len(word) >= 4 and word.strip(string.punctuation) != \"\":\n",
    "        reagan_text.append(word.lower())\n",
    "\n",
    "reagan_corpus = [ ]\n",
    "reagan_corpus.append(reagan_text)\n",
    "\n",
    "reagan_dictionary = gensim.corpora.Dictionary(reagan_corpus)\n",
    "reagan_gensim = [ ]\n",
    "for document in reagan_corpus:\n",
    "    reagan_gensim.append(reagan_dictionary.doc2bow(document))\n",
    "\n",
    "reagan_model = gensim.models.ldamodel.LdaModel(reagan_gensim,\n",
    "                                               num_topics = 5,\n",
    "                                               id2word = reagan_dictionary,\n",
    "                                               passes = 20, iterations = 500,\n",
    "                                               alpha = \"asymmetric\",\n",
    "                                               random_state = 0)\n",
    "\n",
    "for topic in reagan_model.print_topics(num_words = 10):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "George H. W. Bush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.007*\"force\" + 0.004*\"iraq\" + 0.004*\"peace\" + 0.004*\"soviet\" + 0.004*\"child\" + 0.004*\"future\" + 0.004*\"security\" + 0.004*\"freedom\" + 0.004*\"change\" + 0.003*\"union\"')\n",
      "(1, '0.000*\"force\" + 0.000*\"security\" + 0.000*\"peace\" + 0.000*\"future\" + 0.000*\"soviet\" + 0.000*\"military\" + 0.000*\"freedom\" + 0.000*\"home\" + 0.000*\"iraq\" + 0.000*\"support\"')\n",
      "(2, '0.000*\"force\" + 0.000*\"iraq\" + 0.000*\"free\" + 0.000*\"child\" + 0.000*\"soviet\" + 0.000*\"future\" + 0.000*\"peace\" + 0.000*\"union\" + 0.000*\"freedom\" + 0.000*\"security\"')\n",
      "(3, '0.000*\"force\" + 0.000*\"change\" + 0.000*\"iraq\" + 0.000*\"stand\" + 0.000*\"soviet\" + 0.000*\"peace\" + 0.000*\"there\" + 0.000*\"together\" + 0.000*\"freedom\" + 0.000*\"economic\"')\n",
      "(4, '0.000*\"force\" + 0.000*\"future\" + 0.000*\"iraq\" + 0.000*\"peace\" + 0.000*\"change\" + 0.000*\"friend\" + 0.000*\"freedom\" + 0.000*\"child\" + 0.000*\"free\" + 0.000*\"family\"')\n"
     ]
    }
   ],
   "source": [
    "bush_path = Path(\"presidential_speeches/bush\")\n",
    "\n",
    "bush_files = [ ]\n",
    "for file in bush_path.iterdir():\n",
    "    if file.name != \".DS_Store\":\n",
    "        bush_files.append(file)\n",
    "bush_files\n",
    "\n",
    "with open(\"output_file\", \"w\") as outfile:\n",
    "    for fname in bush_files:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "with open(\"output_file\") as f:\n",
    "    bush_uncleaned = f.read()\n",
    "\n",
    "bush_tagged = nltk.pos_tag(nltk.word_tokenize(bush_uncleaned))\n",
    "\n",
    "bush_lemmatized = [ ]\n",
    "for word, tag in bush_tagged:\n",
    "    wntag = penntag_to_wordnettag(tag)\n",
    "    bush_lemmatized.append(lemmatizer.lemmatize(word, wntag))\n",
    "\n",
    "bush_text = [ ]\n",
    "for word in bush_lemmatized:\n",
    "    if word not in stopwords and word not in common_terms and len(word) >= 4 and word.strip(string.punctuation) != \"\":\n",
    "        bush_text.append(word.lower())\n",
    "\n",
    "bush_corpus = [ ]\n",
    "bush_corpus.append(bush_text)\n",
    "\n",
    "bush_dictionary = gensim.corpora.Dictionary(bush_corpus)\n",
    "bush_gensim = [ ]\n",
    "for document in bush_corpus:\n",
    "    bush_gensim.append(bush_dictionary.doc2bow(document))\n",
    "bush_gensim\n",
    "\n",
    "bush_model = gensim.models.ldamodel.LdaModel(bush_gensim,\n",
    "                                               num_topics = 5,\n",
    "                                               id2word = bush_dictionary,\n",
    "                                               passes = 20, iterations = 500,\n",
    "                                               alpha = \"asymmetric\",\n",
    "                                               random_state = 0)\n",
    "\n",
    "for topic in bush_model.print_topics(num_words = 10):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "George W. Bush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.000*\"iraq\" + 0.000*\"terrorist\" + 0.000*\"security\" + 0.000*\"iraqi\" + 0.000*\"freedom\" + 0.000*\"citizen\" + 0.000*\"health\" + 0.000*\"peace\" + 0.000*\"free\" + 0.000*\"border\"')\n",
      "(1, '0.000*\"iraq\" + 0.000*\"terrorist\" + 0.000*\"freedom\" + 0.000*\"security\" + 0.000*\"woman\" + 0.000*\"force\" + 0.000*\"health\" + 0.000*\"regime\" + 0.000*\"citizen\" + 0.000*\"weapon\"')\n",
      "(2, '0.008*\"iraq\" + 0.006*\"terrorist\" + 0.005*\"security\" + 0.005*\"freedom\" + 0.004*\"citizen\" + 0.004*\"iraqi\" + 0.004*\"child\" + 0.003*\"peace\" + 0.003*\"health\" + 0.003*\"force\"')\n",
      "(3, '0.000*\"freedom\" + 0.000*\"iraq\" + 0.000*\"security\" + 0.000*\"terrorist\" + 0.000*\"child\" + 0.000*\"iraqi\" + 0.000*\"citizen\" + 0.000*\"health\" + 0.000*\"human\" + 0.000*\"enemy\"')\n",
      "(4, '0.000*\"terrorist\" + 0.000*\"security\" + 0.000*\"iraq\" + 0.000*\"freedom\" + 0.000*\"citizen\" + 0.000*\"iraqi\" + 0.000*\"peace\" + 0.000*\"worker\" + 0.000*\"woman\" + 0.000*\"economy\"')\n"
     ]
    }
   ],
   "source": [
    "gwbush_path = Path(\"presidential_speeches/gwbush\")\n",
    "\n",
    "gwbush_files = [ ]\n",
    "for file in gwbush_path.iterdir():\n",
    "    if file.name != \".DS_Store\":\n",
    "        gwbush_files.append(file)\n",
    "gwbush_files\n",
    "\n",
    "with open(\"output_file\", \"w\") as outfile:\n",
    "    for fname in gwbush_files:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "with open(\"output_file\") as f:\n",
    "    gwbush_uncleaned = f.read()\n",
    "\n",
    "gwbush_tagged = nltk.pos_tag(nltk.word_tokenize(gwbush_uncleaned))\n",
    "\n",
    "gwbush_lemmatized = [ ]\n",
    "for word, tag in gwbush_tagged:\n",
    "    wntag = penntag_to_wordnettag(tag)\n",
    "    gwbush_lemmatized.append(lemmatizer.lemmatize(word, wntag))\n",
    "\n",
    "gwbush_text = [ ]\n",
    "for word in gwbush_lemmatized:\n",
    "    if word not in stopwords and word not in common_terms and len(word) >= 4 and word.strip(string.punctuation) != \"\":\n",
    "        gwbush_text.append(word.lower())\n",
    "\n",
    "gwbush_corpus = [ ]\n",
    "gwbush_corpus.append(gwbush_text)\n",
    "\n",
    "gwbush_dictionary = gensim.corpora.Dictionary(gwbush_corpus)\n",
    "gwbush_gensim = [ ]\n",
    "for document in gwbush_corpus:\n",
    "    gwbush_gensim.append(gwbush_dictionary.doc2bow(document))\n",
    "gwbush_gensim\n",
    "\n",
    "gwbush_model = gensim.models.ldamodel.LdaModel(gwbush_gensim,\n",
    "                                               num_topics = 5,\n",
    "                                               id2word = gwbush_dictionary,\n",
    "                                               passes = 20, iterations = 500,\n",
    "                                               alpha = \"asymmetric\",\n",
    "                                               random_state = 0)\n",
    "\n",
    "for topic in gwbush_model.print_topics(num_words = 10):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.006*\"deal\" + 0.005*\"build\" + 0.005*\"money\" + 0.005*\"trade\" + 0.005*\"wall\" + 0.004*\"border\" + 0.004*\"remember\" + 0.004*\"change\" + 0.004*\"fight\" + 0.004*\"mexico\"')\n",
      "(1, '0.000*\"money\" + 0.000*\"remember\" + 0.000*\"deal\" + 0.000*\"border\" + 0.000*\"campaign\" + 0.000*\"wall\" + 0.000*\"build\" + 0.000*\"mexico\" + 0.000*\"what\" + 0.000*\"trade\"')\n",
      "(2, '0.000*\"deal\" + 0.000*\"trade\" + 0.000*\"build\" + 0.000*\"wall\" + 0.000*\"money\" + 0.000*\"border\" + 0.000*\"four\" + 0.000*\"keep\" + 0.000*\"thousand\" + 0.000*\"mexico\"')\n",
      "(3, '0.000*\"money\" + 0.000*\"build\" + 0.000*\"trade\" + 0.000*\"deal\" + 0.000*\"border\" + 0.000*\"stop\" + 0.000*\"wall\" + 0.000*\"hear\" + 0.000*\"remember\" + 0.000*\"mexico\"')\n",
      "(4, '0.000*\"money\" + 0.000*\"deal\" + 0.000*\"build\" + 0.000*\"change\" + 0.000*\"wall\" + 0.000*\"border\" + 0.000*\"remember\" + 0.000*\"trade\" + 0.000*\"fight\" + 0.000*\"everybody\"')\n"
     ]
    }
   ],
   "source": [
    "trump_path = Path(\"presidential_speeches/trump\")\n",
    "\n",
    "trump_files = [ ]\n",
    "for file in trump_path.iterdir():\n",
    "    if file.name != \".DS_Store\":\n",
    "        trump_files.append(file)\n",
    "trump_files\n",
    "\n",
    "with open(\"output_file\", \"w\") as outfile:\n",
    "    for fname in trump_files:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "with open(\"output_file\") as f:\n",
    "    trump_uncleaned = f.read()\n",
    "    \n",
    "trump_tagged = nltk.pos_tag(nltk.word_tokenize(trump_uncleaned))\n",
    "\n",
    "trump_lemmatized = [ ]\n",
    "for word, tag in trump_tagged:\n",
    "    wntag = penntag_to_wordnettag(tag)\n",
    "    trump_lemmatized.append(lemmatizer.lemmatize(word, wntag))\n",
    "\n",
    "trump_text = [ ]\n",
    "for word in trump_lemmatized:\n",
    "    if word not in stopwords and word not in common_terms and len(word) >= 4 and word.strip(string.punctuation) != \"\":\n",
    "        trump_text.append(word.lower())\n",
    "\n",
    "trump_corpus = [ ]\n",
    "trump_corpus.append(trump_text)\n",
    "\n",
    "trump_dictionary = gensim.corpora.Dictionary(trump_corpus)\n",
    "trump_gensim = [ ]\n",
    "for document in trump_corpus:\n",
    "    trump_gensim.append(trump_dictionary.doc2bow(document))\n",
    "trump_gensim\n",
    "\n",
    "trump_model = gensim.models.ldamodel.LdaModel(trump_gensim,\n",
    "                                               num_topics = 5,\n",
    "                                               id2word = trump_dictionary,\n",
    "                                               passes = 20, iterations = 500,\n",
    "                                               alpha = \"asymmetric\",\n",
    "                                               random_state = 0)\n",
    "\n",
    "for topic in trump_model.print_topics(num_words = 10):\n",
    "    print(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
